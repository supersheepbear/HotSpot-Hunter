# coding=utf-8
"""
é‡è¦æ–°é—»æ¨é€æ¨¡å—

å½“æ–°å¢æ–°é—»çš„é‡è¦æ€§è¯„çº§ä¸º critical æˆ– high æ—¶ï¼Œè‡ªåŠ¨æ¨é€åˆ°æ‰€æœ‰é…ç½®çš„æ¸ é“
"""

from typing import List, Dict, Optional, Callable
from datetime import datetime


def _categorize_news(stats: List[Dict]) -> Dict[str, List[Dict]]:
    """
    æ ¹æ®å…³é”®è¯å°†æ–°é—»åˆ†ç±»

    Args:
        stats: æ–°é—»ç»Ÿè®¡æ•°æ®

    Returns:
        åˆ†ç±»åçš„æ–°é—»å­—å…¸
    """
    categories = {
        "æ”¿æ²»å¤–äº¤": [],
        "ç»æµé‡‘è": [],
        "ç§‘æŠ€åˆ›æ–°": [],
        "ç¤¾ä¼šæ°‘ç”Ÿ": [],
        "å›½é™…å…³ç³»": [],
        "è‡ªç„¶ç¾å®³": [],
        "å…¶ä»–": []
    }

    # å…³é”®è¯æ˜ å°„
    keyword_map = {
        "æ”¿æ²»å¤–äº¤": ["æ”¿ç­–", "å¤–äº¤", "æ”¿åºœ", "å›½åŠ¡é™¢", "ä¼šè®®", "æ³•å¾‹", "æ”¿æ²»"],
        "ç»æµé‡‘è": ["ç»æµ", "é‡‘è", "è‚¡å¸‚", "æŠ•èµ„", "é“¶è¡Œ", "è´§å¸", "è´¸æ˜“", "GDP", "è´¢æŠ¥", "ä¸Šå¸‚", "èèµ„"],
        "ç§‘æŠ€åˆ›æ–°": ["ç§‘æŠ€", "AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "æŠ€æœ¯", "äº’è”ç½‘", "è½¯ä»¶", "ç¡¬ä»¶", "åˆ›æ–°", "ç ”å‘"],
        "ç¤¾ä¼šæ°‘ç”Ÿ": ["ç¤¾ä¼š", "æ•™è‚²", "åŒ»ç–—", "å°±ä¸š", "æ°‘ç”Ÿ", "å®‰å…¨", "äº‹æ•…"],
        "å›½é™…å…³ç³»": ["å›½é™…", "æˆ˜äº‰", "å†²çª", "åˆ¶è£", "åè®®", "å³°ä¼š"],
        "è‡ªç„¶ç¾å®³": ["åœ°éœ‡", "å°é£", "æ´ªæ°´", "ç¾å®³", "ç–«æƒ…", "ç«ç¾"]
    }

    for stat in stats:
        titles = stat.get("titles", [])
        word = stat.get("word", "")

        # æ ¹æ®å…³é”®è¯åˆ¤æ–­åˆ†ç±»
        categorized = False
        for category, keywords in keyword_map.items():
            if any(kw in word or any(kw in title.get("title", "") for title in titles) for kw in keywords):
                categories[category].extend(titles)
                categorized = True
                break

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°åˆ†ç±»ï¼Œæ”¾å…¥"å…¶ä»–"
        if not categorized:
            categories["å…¶ä»–"].extend(titles)

    # ç§»é™¤ç©ºåˆ†ç±»
    return {k: v for k, v in categories.items() if v}


def send_important_news_to_all_channels(
    important_news: List[Dict],
    notification_config: Dict,
    get_time_func: Optional[Callable] = None,
    split_content_func: Optional[Callable] = None,
) -> Dict[str, bool]:
    """
    æ¨é€é‡è¦æ–°é—»åˆ°æ‰€æœ‰é…ç½®çš„æ¸ é“
    
    Args:
        important_news: é‡è¦æ–°é—»åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - title: æ–°é—»æ ‡é¢˜
            - platform_name: å¹³å°åç§°
            - platform_id: å¹³å°ID
            - rank: æ’å
            - importance: é‡è¦æ€§è¯„çº§ ('critical' æˆ– 'high')
            - url: æ–°é—»é“¾æ¥ï¼ˆå¯é€‰ï¼‰
        notification_config: æ¨é€é€šçŸ¥é…ç½®å­—å…¸
        get_time_func: è·å–å½“å‰æ—¶é—´çš„å‡½æ•°
        split_content_func: å†…å®¹åˆ†æ‰¹å‡½æ•°
    
    Returns:
        Dict[str, bool]: æ¯ä¸ªæ¸ é“çš„å‘é€ç»“æœ
    """
    if not important_news:
        return {}
    
    # è·å–å½“å‰æ—¶é—´
    if get_time_func:
        now = get_time_func()
    else:
        now = datetime.now()
    
    # å°†é‡è¦æ–°é—»è½¬æ¢ä¸º report_data æ ¼å¼
    report_data = _convert_important_news_to_report_data(important_news)
    
    # åˆ›å»º NotificationDispatcher
    from app.notification import NotificationDispatcher
    
    # å¦‚æœæ²¡æœ‰æä¾› split_content_funcï¼Œä½¿ç”¨é»˜è®¤å®ç°
    if split_content_func is None:
        # å¯¼å…¥å†…å®¹æ¸²æŸ“å’Œåˆ†æ‰¹å‡½æ•°
        from app.notification.renderer import (
            render_feishu_content,
            render_dingtalk_content,
        )
        from app.notification.batch import truncate_to_bytes

        def default_split_func(
            report_data: Dict,
            channel: str,
            update_info: Optional[Dict] = None,
            max_bytes: int = 4000,
            mode: str = "daily",
            **kwargs
        ) -> List[str]:
            """é»˜è®¤çš„å†…å®¹åˆ†æ‰¹å‡½æ•°"""
            # æ ¹æ®æ¸ é“é€‰æ‹©æ¸²æŸ“å‡½æ•°
            if channel == "feishu":
                content = render_feishu_content(report_data, update_info, mode)
            elif channel == "dingtalk":
                content = render_dingtalk_content(report_data, update_info, mode)
            else:
                # å…¶ä»–æ¸ é“ä½¿ç”¨ç®€å•çš„æ–‡æœ¬æ ¼å¼ï¼ˆDiscord, Telegramç­‰ï¼‰
                content = ""

                # å¤„ç† stats ä¸­çš„é‡è¦æ–°é—»
                if report_data.get("stats"):
                    # stats å·²ç»åœ¨ _convert_important_news_to_report_data ä¸­æŒ‰ç±»åˆ«åˆ†ç»„
                    # ç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦å†æ¬¡è°ƒç”¨ _categorize_news

                    # ç»Ÿè®¡æ€»æ•°
                    total_count = sum(len(stat.get("titles", [])) for stat in report_data["stats"])

                    # æ ‡é¢˜
                    content += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    content += f"ğŸ“° é‡è¦æ–°é—» ({total_count}æ¡)\n"
                    content += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

                    # æŒ‰åˆ†ç±»è¾“å‡ºï¼ˆstats ä¸­æ¯ä¸ªå…ƒç´ å°±æ˜¯ä¸€ä¸ªç±»åˆ«ï¼‰
                    for stat in report_data["stats"]:
                        category_name = stat.get("word", "")  # ä¾‹å¦‚ "ğŸ”´ æ”¿æ²»å¤–äº¤"
                        news_list = stat.get("titles", [])

                        if not news_list:
                            continue

                        content += f"{category_name}\n"

                        for title_info in news_list:
                            title = title_info.get("title", "")
                            source = title_info.get("source_name", "")
                            url = title_info.get("url", "")

                            if url:
                                content += f"â€¢ {title} <{url}> | {source}\n"
                            else:
                                content += f"â€¢ {title} | {source}\n"

                        content += "\n"

                # å¤„ç† new_titlesï¼ˆå¦‚æœæœ‰ï¼‰
                elif report_data.get("new_titles"):
                    content += "ğŸ“° é‡è¦æ–°é—»æ¨é€\n\n"
                    for platform_id, titles in report_data["new_titles"].items():
                        platform_name = report_data.get("id_to_name", {}).get(platform_id, platform_id)
                        content += f"ã€{platform_name}ã€‘\n"
                        for title_info in titles[:10]:
                            title = title_info.get("title", "")
                            content += f"â€¢ {title}\n"
                        content += "\n"

            # åˆ†æ‰¹å¤„ç†
            if not content:
                return []

            content_bytes = content.encode('utf-8')
            if len(content_bytes) <= max_bytes:
                return [content]

            # éœ€è¦åˆ†æ‰¹
            batches = []
            current_batch = ""
            current_size = 0

            for line in content.split('\n'):
                line_bytes = (line + '\n').encode('utf-8')
                line_size = len(line_bytes)

                if current_size + line_size > max_bytes:
                    if current_batch:
                        batches.append(current_batch)
                    current_batch = line + '\n'
                    current_size = line_size
                else:
                    current_batch += line + '\n'
                    current_size += line_size

            if current_batch:
                batches.append(current_batch)

            return batches

        split_content_func = default_split_func
    
    dispatcher = NotificationDispatcher(
        config=notification_config,
        get_time_func=get_time_func or (lambda: datetime.now()),
        split_content_func=split_content_func,
    )
    
    # ä½¿ç”¨ dispatcher æ¨é€åˆ°æ‰€æœ‰æ¸ é“
    report_type = f"é‡è¦æ–°é—»æ¨é€ ({len(important_news)} æ¡)"
    
    # è®¾ç½®æ˜¾ç¤ºåŒºåŸŸé…ç½®ï¼ˆåªæ˜¾ç¤ºé‡è¦æ–°é—»ï¼Œä¸æ˜¾ç¤ºå…¶ä»–å†…å®¹ï¼‰
    display_regions_config = {
        "HOTLIST": True,  # æ˜¾ç¤ºçƒ­æ¦œï¼ˆé‡è¦æ–°é—»ï¼‰
        "RSS": False,  # ä¸æ˜¾ç¤ºRSS
        "AI_ANALYSIS": False,  # ä¸æ˜¾ç¤ºAIåˆ†æ
        "STANDALONE": False,  # ä¸æ˜¾ç¤ºç‹¬ç«‹å±•ç¤ºåŒº
    }
    
    # æ›´æ–°é…ç½®ä¸­çš„æ˜¾ç¤ºåŒºåŸŸè®¾ç½®ï¼ˆä¸´æ—¶è¦†ç›–ï¼‰
    original_display = notification_config.get("DISPLAY", {})
    notification_config["DISPLAY"] = {
        "REGIONS": display_regions_config
    }
    
    results = dispatcher.dispatch_all(
        report_data=report_data,
        report_type=report_type,
        mode="incremental",  # å¢é‡æ¨¡å¼
    )
    
    # æ¢å¤åŸå§‹é…ç½®
    notification_config["DISPLAY"] = original_display
    
    return results


def _convert_important_news_to_report_data(important_news: List[Dict]) -> Dict:
    """
    å°†é‡è¦æ–°é—»åˆ—è¡¨è½¬æ¢ä¸º report_data æ ¼å¼

    Args:
        important_news: é‡è¦æ–°é—»åˆ—è¡¨

    Returns:
        report_data æ ¼å¼çš„å­—å…¸
    """
    # å…³é”®è¯æ˜ å°„ï¼ˆç”¨äºåˆ†ç±»ï¼‰- åŒ…å«ä¸­è‹±æ–‡å…³é”®è¯
    keyword_map = {
        "æ”¿æ²»å¤–äº¤": [
            # ä¸­æ–‡
            "æ”¿ç­–", "å¤–äº¤", "æ”¿åºœ", "å›½åŠ¡é™¢", "ä¼šè®®", "æ³•å¾‹", "æ”¿æ²»", "éƒ¨é•¿", "å®˜å‘˜", "å…š",
            "é˜²åŠ¡", "é¢„ç®—", "ç¨", "å¢å€¼ç¨", "ç«‹æ³•", "è®®ä¼š", "é€‰ä¸¾", "æŠ•ç¥¨", "æ°‘ä¸»å…š", "å…±å’Œå…š",
            # è‹±æ–‡
            "government", "policy", "election", "vote", "congress", "senate", "minister"
        ],
        "ç»æµé‡‘è": [
            # ä¸­æ–‡
            "ç»æµ", "é‡‘è", "è‚¡å¸‚", "æŠ•èµ„", "é“¶è¡Œ", "è´§å¸", "è´¸æ˜“", "GDP", "è´¢æŠ¥", "ä¸Šå¸‚",
            "èèµ„", "äº¤ä»˜", "é”€é‡", "å‡ºå£", "è¿›å£", "åŠå¯¼ä½“", "è®¢å•", "å¸‚å€¼", "ä¼°å€¼",
            # è‹±æ–‡
            "economy", "finance", "stock", "market", "investment", "trade", "export", "import"
        ],
        "ç§‘æŠ€åˆ›æ–°": [
            # ä¸­æ–‡
            "ç§‘æŠ€", "AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "æŠ€æœ¯", "äº’è”ç½‘", "è½¯ä»¶", "ç¡¬ä»¶", "åˆ›æ–°", "ç ”å‘",
            "å«æ˜Ÿ", "æ•°æ®", "ç®—æ³•", "æ¨¡å‹", "å¼€æº", "GitHub", "microsoft", "anthropics", "BitNet",
            "æ­¼-20", "æˆ˜æœº", "æ— äººæœº", "æœºå™¨äºº", "è‡ªåŠ¨é©¾é©¶", "å…‰åˆ", "èƒ½æº",
            # è‹±æ–‡
            "AI", "technology", "software", "hardware", "algorithm", "model", "bot", "botnet",
            "Wikipedia", "WhatsApp", "GPS", "autonomous", "drone", "prompt injection", "social media"
        ],
        "ç¤¾ä¼šæ°‘ç”Ÿ": [
            # ä¸­æ–‡
            "ç¤¾ä¼š", "æ•™è‚²", "åŒ»ç–—", "å°±ä¸š", "æ°‘ç”Ÿ", "å®‰å…¨", "äº‹æ•…", "è¯Šç–—", "ä¸­æ¯’", "æ­»äº¡",
            "å…¥ç‹±", "çŠ¯ç½ª", "æ¡ˆä»¶", "æ¯’è¯", "é™„ç‰‡", "æ•‘å¿ƒä¸¸",
            # è‹±æ–‡
            "health", "education", "safety", "dies", "death", "smallpox", "eradicate"
        ],
        "å›½é™…å…³ç³»": [
            # ä¸­æ–‡
            "å›½é™…", "æˆ˜äº‰", "å†²çª", "åˆ¶è£", "åè®®", "å³°ä¼š", "ä¼Šæœ—", "ä»¥è‰²åˆ—", "åŠ æ²™", "ä¹Œå…‹å…°",
            "ä¿„", "ç¾å›½", "æ¬§ç›Ÿ", "å°åº¦", "è°ˆåˆ¤", "å†›æ¼”", "è¢­å‡»", "åœç«",
            # è‹±æ–‡
            "international", "war", "conflict", "Iran", "Israel", "Gaza", "Ukraine", "Russia"
        ],
        "è‡ªç„¶ç¾å®³": [
            # ä¸­æ–‡
            "åœ°éœ‡", "å°é£", "æ´ªæ°´", "ç¾å®³", "ç–«æƒ…", "ç«ç¾", "å´©å¡Œ", "çŸ¿éš¾",
            # è‹±æ–‡
            "disaster", "earthquake", "flood", "typhoon", "pandemic"
        ],
        "ä½“è‚²èµ›äº‹": [
            # ä¸­æ–‡
            "æ¾³ç½‘", "å† å†›", "å¤ºå† ", "æ¯”èµ›", "è¿åŠ¨", "çƒ", "èµ›", "è±å·´é‡‘å¨œ", "è¨å·´ä¼¦å¡",
            "å¤§æ»¡è´¯", "å†³èµ›", "ç½‘çƒ",
            # è‹±æ–‡
            "sport", "champion", "game", "match", "tennis", "Australian Open"
        ],
    }

    # æŒ‰ç±»åˆ«åˆ†ç»„æ–°é—»
    categorized_news = {category: [] for category in keyword_map.keys()}
    categorized_news["å…¶ä»–"] = []

    for news in important_news:
        title = news.get("title", "")
        categorized = False

        # æ ¹æ®æ ‡é¢˜å†…å®¹åˆ¤æ–­åˆ†ç±»
        for category, keywords in keyword_map.items():
            if any(kw in title for kw in keywords):
                categorized_news[category].append(news)
                categorized = True
                break

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°åˆ†ç±»ï¼Œæ”¾å…¥"å…¶ä»–"
        if not categorized:
            categorized_news["å…¶ä»–"].append(news)

    # æ„å»º statsï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
    stats = []

    # ç±»åˆ«å›¾æ ‡æ˜ å°„
    category_icons = {
        "æ”¿æ²»å¤–äº¤": "ğŸ”´",
        "ç»æµé‡‘è": "ğŸ’°",
        "ç§‘æŠ€åˆ›æ–°": "ğŸ’»",
        "ç¤¾ä¼šæ°‘ç”Ÿ": "ğŸ‘¥",
        "å›½é™…å…³ç³»": "ğŸŒ",
        "è‡ªç„¶ç¾å®³": "âš ï¸",
        "ä½“è‚²èµ›äº‹": "ğŸ†",
        "å…¶ä»–": "ğŸ“Œ"
    }

    for category, news_list in categorized_news.items():
        if not news_list:
            continue

        icon = category_icons.get(category, "ğŸ“Œ")

        # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„æ–°é—»æ•°é‡
        print(f"[é‡è¦æ–°é—»åˆ†ç±»] {icon} {category}: {len(news_list)} æ¡")
        for news in news_list:
            print(f"  - {news.get('title', '')[:50]}...")

        stats.append({
            "word": f"{icon} {category}",
            "count": len(news_list),
            "titles": [
                {
                    "title": news.get("title", ""),
                    "source_name": news.get("platform_name", ""),
                    "url": news.get("url", ""),
                    "mobile_url": news.get("url", ""),
                    "ranks": [news.get("rank", 0)],
                    "rank_threshold": 10,
                    "time_display": "",
                    "count": 1,
                    "is_new": True,
                }
                for news in news_list
            ],
        })

    # æ„å»º id_to_name æ˜ å°„
    id_to_name = {}
    for news in important_news:
        platform_id = news.get("platform_id", "")
        platform_name = news.get("platform_name", "")
        if platform_id and platform_name:
            id_to_name[platform_id] = platform_name

    return {
        "stats": stats,
        "new_titles": [],
        "failed_ids": [],
        "id_to_name": id_to_name,
        "total_new_count": len(important_news),
    }


# ä¿ç•™æ—§å‡½æ•°åä»¥ä¿æŒå…¼å®¹æ€§ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨ send_important_news_to_all_channelsï¼‰
def send_important_news_to_feishu(
    important_news: List[Dict],
    webhook_url: str,
    get_time_func=None,
) -> bool:
    """
    æ¨é€é‡è¦æ–°é—»åˆ°é£ä¹¦ï¼ˆå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ send_important_news_to_all_channelsï¼‰
    
    æ­¤å‡½æ•°ä¿ç•™ä»…ä¸ºå‘åå…¼å®¹ï¼Œå®é™…ä¼šè°ƒç”¨æ–°çš„å¤šæ¸ é“æ¨é€å‡½æ•°
    """
    import requests
    
    if not important_news:
        return False
    
    if not webhook_url:
        print("[é‡è¦æ–°é—»æ¨é€] æœªé…ç½®é£ä¹¦ Webhook URLï¼Œè·³è¿‡æ¨é€")
        return False
    
    # è·å–å½“å‰æ—¶é—´
    if get_time_func:
        now = get_time_func()
    else:
        now = datetime.now()
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹
    importance_labels = {
        "critical": "ğŸ”´ å…³é”®",
        "high": "ğŸŸ  é‡è¦",
    }
    
    content_parts = []
    content_parts.append("ğŸ“° é‡è¦æ–°é—»æ¨é€")
    content_parts.append(f"æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}")
    content_parts.append("")  # ç©ºè¡Œ
    
    for idx, news in enumerate(important_news, 1):
        title = news.get("title", "")
        platform_name = news.get("platform_name", "")
        rank = news.get("rank", 0)
        importance = news.get("importance", "")
        url = news.get("url", "")
        
        importance_label = importance_labels.get(importance, importance)
        
        # æ„å»ºæ–°é—»æ¡ç›®
        news_lines = []
        news_lines.append(f"{idx}. {importance_label} | {title}")
        
        # æ·»åŠ å¹³å°å’Œæ’åä¿¡æ¯
        info_parts = []
        if platform_name:
            info_parts.append(f"å¹³å°: {platform_name}")
        if rank > 0:
            info_parts.append(f"æ’å: #{rank}")
        if info_parts:
            news_lines.append("   " + " | ".join(info_parts))
        
        # æ·»åŠ é“¾æ¥
        if url:
            news_lines.append(f"   é“¾æ¥: {url}")
        
        content_parts.extend(news_lines)
        content_parts.append("")  # ç©ºè¡Œåˆ†éš”
    
    full_content = "\n".join(content_parts)
    
    # æ„å»ºé£ä¹¦æ¶ˆæ¯ payload
    payload = {
        "msg_type": "text",
        "content": {
            "text": full_content,
        },
    }
    
    headers = {"Content-Type": "application/json"}
    
    try:
        response = requests.post(webhook_url, headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            if result.get("code") == 0 or result.get("StatusCode") == 0:
                print(f"[é‡è¦æ–°é—»æ¨é€] æˆåŠŸæ¨é€ {len(important_news)} æ¡é‡è¦æ–°é—»åˆ°é£ä¹¦")
                return True
            else:
                error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å¤±è´¥ï¼Œé”™è¯¯ï¼š{error_msg}")
                return False
        else:
            print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            print(f"[é‡è¦æ–°é—»æ¨é€] å“åº”å†…å®¹ï¼š{response.text}")
            return False
    except Exception as e:
        print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False
    """
    æ¨é€é‡è¦æ–°é—»åˆ°é£ä¹¦
    
    Args:
        important_news: é‡è¦æ–°é—»åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - title: æ–°é—»æ ‡é¢˜
            - platform_name: å¹³å°åç§°
            - rank: æ’å
            - importance: é‡è¦æ€§è¯„çº§ ('critical' æˆ– 'high')
            - url: æ–°é—»é“¾æ¥ï¼ˆå¯é€‰ï¼‰
        webhook_url: é£ä¹¦ Webhook URL
        get_time_func: è·å–å½“å‰æ—¶é—´çš„å‡½æ•°
    
    Returns:
        bool: å‘é€æ˜¯å¦æˆåŠŸ
    """
    if not important_news:
        return False
    
    if not webhook_url:
        print("[é‡è¦æ–°é—»æ¨é€] æœªé…ç½®é£ä¹¦ Webhook URLï¼Œè·³è¿‡æ¨é€")
        return False
    
    # è·å–å½“å‰æ—¶é—´
    if get_time_func:
        now = get_time_func()
    else:
        now = datetime.now()
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹
    importance_labels = {
        "critical": "ğŸ”´ å…³é”®",
        "high": "ğŸŸ  é‡è¦",
    }
    
    content_parts = []
    content_parts.append("ğŸ“° é‡è¦æ–°é—»æ¨é€")
    content_parts.append(f"æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}")
    content_parts.append("")  # ç©ºè¡Œ
    
    for idx, news in enumerate(important_news, 1):
        title = news.get("title", "")
        platform_name = news.get("platform_name", "")
        rank = news.get("rank", 0)
        importance = news.get("importance", "")
        url = news.get("url", "")
        
        importance_label = importance_labels.get(importance, importance)
        
        # æ„å»ºæ–°é—»æ¡ç›®
        news_lines = []
        news_lines.append(f"{idx}. {importance_label} | {title}")
        
        # æ·»åŠ å¹³å°å’Œæ’åä¿¡æ¯
        info_parts = []
        if platform_name:
            info_parts.append(f"å¹³å°: {platform_name}")
        if rank > 0:
            info_parts.append(f"æ’å: #{rank}")
        if info_parts:
            news_lines.append("   " + " | ".join(info_parts))
        
        # æ·»åŠ é“¾æ¥
        if url:
            news_lines.append(f"   é“¾æ¥: {url}")
        
        content_parts.extend(news_lines)
        content_parts.append("")  # ç©ºè¡Œåˆ†éš”
    
    full_content = "\n".join(content_parts)
    
    # æ„å»ºé£ä¹¦æ¶ˆæ¯ payload
    payload = {
        "msg_type": "text",
        "content": {
            "text": full_content,
        },
    }
    
    headers = {"Content-Type": "application/json"}
    
    try:
        response = requests.post(webhook_url, headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            if result.get("code") == 0 or result.get("StatusCode") == 0:
                print(f"[é‡è¦æ–°é—»æ¨é€] æˆåŠŸæ¨é€ {len(important_news)} æ¡é‡è¦æ–°é—»åˆ°é£ä¹¦")
                return True
            else:
                error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å¤±è´¥ï¼Œé”™è¯¯ï¼š{error_msg}")
                return False
        else:
            print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            print(f"[é‡è¦æ–°é—»æ¨é€] å“åº”å†…å®¹ï¼š{response.text}")
            return False
    except Exception as e:
        print(f"[é‡è¦æ–°é—»æ¨é€] æ¨é€å‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False
